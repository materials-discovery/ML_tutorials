{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2AJ6LMKtIfW",
        "outputId": "fc90ff7a-36ff-4554-d485-96de183dc8cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8E8yw-lf_6tf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Data Preparation\n",
        "# Dummy function and variable for illustration\n",
        "def preprocess_smiles(smiles_list):\n",
        "    # This function should tokenize and encode SMILES strings\n",
        "    # Step 1 & 2: Tokenize SMILES and build character index\n",
        "    tokenizer = Tokenizer(char_level=True)  # char_level=True tokenizes at the character level\n",
        "    tokenizer.fit_on_texts(smiles_list['SMILE_Organic_linker_1'])\n",
        "\n",
        "    # Step 3: Encode SMILES strings\n",
        "    sequences = tokenizer.texts_to_sequences(smiles_list['SMILE_Organic_linker_1'])\n",
        "\n",
        "    # Step 4: Padding\n",
        "    max_len = max(len(s) for s in sequences)  # You might choose to set this manually\n",
        "    encoded_smiles = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "    # For simplicity, this is just a placeholder\n",
        "    return np.array(encoded_smiles),max_len\n",
        "\n",
        "# Example SMILES data (normally you would load this from a file)\n",
        "smiles_data = pd.read_csv(\"/content/smiles.csv\")\n",
        "\n",
        "max_smiles_length = max(len(s) for s in smiles_data)\n",
        "encoded_smiles,max_len = preprocess_smiles(smiles_data)\n"
      ],
      "metadata": {
        "id": "zpJjV_ww_7zk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Define GAN Architecture\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        Dense(128, activation='relu', input_dim=latent_dim),\n",
        "        Reshape((32, 4)),\n",
        "        LSTM(64, return_sequences=True),\n",
        "        Flatten(),\n",
        "        Dense(output_dim, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        LSTM(64, input_shape=(input_dim, 1), return_sequences=True),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "latent_dim = 10\n",
        "generator = build_generator(latent_dim, max_smiles_length)\n",
        "discriminator = build_discriminator(max_smiles_length)\n"
      ],
      "metadata": {
        "id": "ocDMElNP_7ws"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Compile GAN\n",
        "# Compile discriminator\n",
        "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Combined model (stacked generator and discriminator)\n",
        "# The generator takes noise as input and generates sequences\n",
        "z = Input(shape=(latent_dim,))\n",
        "smiles = generator(z)\n",
        "\n",
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# The discriminator takes generated images as input and determines validity\n",
        "validity = discriminator(smiles)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "combined = Model(z, validity)\n",
        "combined.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "lE_zwoz7_7t8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Training Loop\n",
        "import numpy as np\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 10\n",
        "sample_interval = 20\n",
        "\n",
        "# Ground truths for real and fake images\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    # Select a random half of images\n",
        "    idx = np.random.randint(0, encoded_smiles.shape[0], batch_size)\n",
        "    real_smiles = encoded_smiles[idx]\n",
        "\n",
        "    # Sample noise and generate a batch of new images\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_smiles = generator.predict(noise)\n",
        "\n",
        "    # Train the discriminator (real classified as ones and generated as zeros)\n",
        "    d_loss_real = discriminator.train_on_batch(real_smiles, valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_smiles, fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Generator\n",
        "    # ---------------------\n",
        "\n",
        "    # Train the generator (wants discriminator to mistake images as real)\n",
        "    g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "    # Plot the progress\n",
        "    print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "    # If at save interval => save generated image samples\n",
        "    if epoch % sample_interval == 0:\n",
        "        # Here you can save or visualize your generated SMILES for inspection\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "oid8Z0bC_7qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6: Generate and Validate SMILES\n",
        "def generate_smiles(generator, latent_dim):\n",
        "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
        "    gen_smiles = generator.predict(noise)\n",
        "    # Here, you need to decode the generated SMILES from the numerical format back to string\n",
        "    # This step is highly dependent on how you encoded the SMILES strings initially\n",
        "    decoded_smiles = 'CCO'  # Placeholder for actual decoding logic\n",
        "    return decoded_smiles\n",
        "\n",
        "generated_smiles = generate_smiles(generator, latent_dim)\n",
        "print(\"Generated SMILES:\", generated_smiles)\n",
        "\n",
        "# Validate with RDKit\n",
        "mol = Chem.MolFromSmiles(generated_smiles)\n",
        "if mol:\n",
        "    print(\"Valid SMILES\")\n",
        "    Draw.MolToImage(mol)\n",
        "else:\n",
        "    print(\"Invalid SMILES\")\n"
      ],
      "metadata": {
        "id": "0TMro6r7ARwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wx9YxGgRAUiM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}